Use Freedman Lab's datasets to create music based on FRs of neurons
Might need to access the raw data at that point

Similar to IJMSTA paper (Horrell, 2020). Except for monkeys!
Doesn't necessarily have to be random

Let's do with facial recognition sofware
	Different emotions for different melodies
	Talk to Darlene Castro (shadows wih motion sensors)
	Talk to Benjamin Whiting (in e-music studio)
	Who composes the melodies heard?
		Me? Or feed to machine learning 
		Maybe even link to Spotify, sort by emotions
	Facial recognition, then trigger random sampling from corpus of music already generated
	Pull data from Spotify